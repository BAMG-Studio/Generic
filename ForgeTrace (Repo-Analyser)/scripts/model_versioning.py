#!/usr/bin/env python3
"""
ForgeTrace ML Model Versioning Utility

Adds metadata to trained models for version tracking, reproducibility, and audit trails.
Supports model serialization with comprehensive training context.

Usage:
    # Add metadata to existing model
    python scripts/model_versioning.py --model models/ip_classifier_rf.pkl --output models/ip_classifier_v2025.11.08.pkl

    # Extract metadata from versioned model
    python scripts/model_versioning.py --inspect models/ip_classifier_v2025.11.08.pkl
"""

import argparse
import hashlib
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional

import joblib
import numpy as np
from sklearn.ensemble import RandomForestClassifier


logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class ModelVersionManager:
    """Manage model versioning and metadata."""
    
    FEATURE_SCHEMA_VERSION = "2025.11.08"
    
    @staticmethod
    def calculate_dataset_hash(dataset_path: str) -> str:
        """Calculate SHA256 hash of training dataset for reproducibility."""
        logger.info(f"Calculating dataset hash for {dataset_path}")
        
        sha256 = hashlib.sha256()
        with open(dataset_path, 'rb') as f:
            while chunk := f.read(8192):
                sha256.update(chunk)
        
        hash_value = sha256.hexdigest()
        logger.info(f"‚úÖ Dataset hash: {hash_value[:16]}...")
        return hash_value
    
    @staticmethod
    def get_dataset_stats(dataset_path: str) -> Dict[str, Any]:
        """Extract statistics from training dataset."""
        logger.info(f"Extracting dataset statistics from {dataset_path}")
        
        label_counts = {}
        total_examples = 0
        
        with open(dataset_path, 'r') as f:
            for line in f:
                example = json.loads(line)
                label = example['label']
                label_counts[label] = label_counts.get(label, 0) + 1
                total_examples += 1
        
        stats = {
            'total_examples': total_examples,
            'label_distribution': label_counts,
            'label_percentages': {
                label: 100 * count / total_examples 
                for label, count in label_counts.items()
            }
        }
        
        logger.info(f"‚úÖ Dataset: {total_examples:,} examples, "
                   f"{len(label_counts)} classes")
        return stats
    
    @staticmethod
    def create_versioned_model(
        model: RandomForestClassifier,
        version: str,
        dataset_path: Optional[str] = None,
        training_metadata: Optional[Dict[str, Any]] = None,
        performance_metrics: Optional[Dict[str, Any]] = None,
        notes: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Create versioned model package with metadata.
        
        Args:
            model: Trained scikit-learn model
            version: Semantic version string (e.g., "2025.11.08.1")
            dataset_path: Path to training dataset JSONL
            training_metadata: Additional training configuration
            performance_metrics: Test set performance metrics
            notes: Human-readable release notes
        
        Returns:
            Dictionary with model and metadata
        """
        logger.info(f"Creating versioned model package: {version}")
        
        # Build metadata
        metadata = {
            'version': version,
            'created_at': datetime.now().isoformat(),
            'feature_schema_version': ModelVersionManager.FEATURE_SCHEMA_VERSION,
            'model_type': type(model).__name__,
            'sklearn_version': joblib.__version__,
            'hyperparameters': model.get_params(),
            'n_features': model.n_features_in_ if hasattr(model, 'n_features_in_') else None,
            'classes': model.classes_.tolist() if hasattr(model, 'classes_') else None,
        }
        
        # Add dataset information
        if dataset_path and Path(dataset_path).exists():
            metadata['dataset'] = {
                'path': str(dataset_path),
                'hash': ModelVersionManager.calculate_dataset_hash(dataset_path),
                'statistics': ModelVersionManager.get_dataset_stats(dataset_path)
            }
        
        # Add training metadata
        if training_metadata:
            metadata['training'] = training_metadata
        
        # Add performance metrics
        if performance_metrics:
            metadata['performance'] = performance_metrics
        
        # Add release notes
        if notes:
            metadata['release_notes'] = notes
        
        # Package model with metadata
        package = {
            'model': model,
            'metadata': metadata
        }
        
        logger.info("‚úÖ Model package created successfully")
        return package
    
    @staticmethod
    def save_versioned_model(package: Dict[str, Any], output_path: str) -> None:
        """Save versioned model package to disk."""
        logger.info(f"Saving versioned model to {output_path}")
        
        joblib.dump(package, output_path, compress=3)
        
        # Also save metadata as JSON for inspection
        metadata_path = Path(output_path).with_suffix('.json')
        with open(metadata_path, 'w') as f:
            # Make metadata JSON-serializable
            serializable_metadata = json.loads(
                json.dumps(package['metadata'], default=str)
            )
            json.dump(serializable_metadata, f, indent=2)
        
        logger.info(f"‚úÖ Saved model to {output_path}")
        logger.info(f"‚úÖ Saved metadata to {metadata_path}")
    
    @staticmethod
    def load_versioned_model(model_path: str) -> Dict[str, Any]:
        """Load versioned model package from disk."""
        logger.info(f"Loading versioned model from {model_path}")
        
        package = joblib.load(model_path)
        
        if 'metadata' not in package:
            logger.warning("‚ö†Ô∏è  Model does not contain version metadata (legacy format)")
            return {'model': package, 'metadata': None}
        
        logger.info(f"‚úÖ Loaded model version {package['metadata']['version']}")
        return package
    
    @staticmethod
    def inspect_model(model_path: str) -> None:
        """Print detailed information about a versioned model."""
        logger.info("=" * 80)
        logger.info("MODEL INSPECTION")
        logger.info("=" * 80)
        
        package = ModelVersionManager.load_versioned_model(model_path)
        
        if package['metadata'] is None:
            logger.error("‚ùå Model does not contain metadata")
            return
        
        meta = package['metadata']
        
        # Basic info
        print(f"\n{'='*80}")
        print(f"Version: {meta['version']}")
        print(f"Created: {meta['created_at']}")
        print(f"Model Type: {meta['model_type']}")
        print(f"Feature Schema: {meta['feature_schema_version']}")
        print(f"Scikit-learn Version: {meta['sklearn_version']}")
        print(f"{'='*80}")
        
        # Model configuration
        print(f"\nüìã MODEL CONFIGURATION")
        print(f"Number of Features: {meta.get('n_features', 'N/A')}")
        print(f"Classes: {', '.join(meta.get('classes', ['N/A']))}")
        print(f"\nHyperparameters:")
        for param, value in sorted(meta.get('hyperparameters', {}).items()):
            print(f"  {param}: {value}")
        
        # Dataset info
        if 'dataset' in meta:
            ds = meta['dataset']
            print(f"\nüìä TRAINING DATASET")
            print(f"Path: {ds['path']}")
            print(f"Hash: {ds['hash'][:16]}...")
            print(f"Total Examples: {ds['statistics']['total_examples']:,}")
            print(f"\nLabel Distribution:")
            for label, pct in sorted(ds['statistics']['label_percentages'].items()):
                count = ds['statistics']['label_distribution'][label]
                print(f"  {label}: {count:,} ({pct:.1f}%)")
        
        # Performance metrics
        if 'performance' in meta:
            perf = meta['performance']
            print(f"\nüéØ PERFORMANCE METRICS")
            for metric, value in sorted(perf.items()):
                if isinstance(value, dict):
                    print(f"\n{metric}:")
                    for k, v in value.items():
                        print(f"  {k}: {v}")
                else:
                    print(f"{metric}: {value}")
        
        # Training metadata
        if 'training' in meta:
            train = meta['training']
            print(f"\n‚öôÔ∏è  TRAINING CONFIGURATION")
            for key, value in sorted(train.items()):
                print(f"{key}: {value}")
        
        # Release notes
        if 'release_notes' in meta:
            print(f"\nüìù RELEASE NOTES")
            print(meta['release_notes'])
        
        print(f"\n{'='*80}")


def main():
    parser = argparse.ArgumentParser(
        description="ForgeTrace ML Model Versioning Utility"
    )
    parser.add_argument(
        '--model',
        type=str,
        help='Path to input model pickle file'
    )
    parser.add_argument(
        '--output',
        type=str,
        help='Path to save versioned model'
    )
    parser.add_argument(
        '--version',
        type=str,
        default=f"{datetime.now().strftime('%Y.%m.%d')}.1",
        help='Semantic version string (default: YYYY.MM.DD.1)'
    )
    parser.add_argument(
        '--dataset',
        type=str,
        default='training_output/dataset/training_dataset.jsonl',
        help='Path to training dataset JSONL'
    )
    parser.add_argument(
        '--inspect',
        type=str,
        help='Inspect metadata of an existing versioned model'
    )
    parser.add_argument(
        '--notes',
        type=str,
        help='Release notes for this model version'
    )
    
    args = parser.parse_args()
    
    # Inspection mode
    if args.inspect:
        ModelVersionManager.inspect_model(args.inspect)
        return
    
    # Versioning mode
    if not args.model or not args.output:
        parser.error("--model and --output are required (or use --inspect)")
    
    # Load existing model
    logger.info(f"Loading model from {args.model}")
    model = joblib.load(args.model)
    
    # If already a package, extract the model
    if isinstance(model, dict) and 'model' in model:
        logger.info("Input is already a versioned package, extracting model...")
        model = model['model']
    
    # Create performance metrics (if available)
    performance_metrics = {
        'test_accuracy': 0.999,  # Replace with actual metrics
        'cross_validation_mean': 0.999,
        'cross_validation_std': 0.0003,
    }
    
    # Create versioned package
    package = ModelVersionManager.create_versioned_model(
        model=model,
        version=args.version,
        dataset_path=args.dataset,
        training_metadata={
            'training_script': 'scripts/train_random_forest.py',
            'feature_extractor': 'forgetrace.training.extractors',
        },
        performance_metrics=performance_metrics,
        notes=args.notes
    )
    
    # Save versioned model
    ModelVersionManager.save_versioned_model(package, args.output)
    
    logger.info("\n‚úÖ Model versioning complete!")
    logger.info(f"üì¶ Versioned model: {args.output}")
    logger.info(f"üìÑ Metadata file: {Path(args.output).with_suffix('.json')}")


if __name__ == '__main__':
    main()
