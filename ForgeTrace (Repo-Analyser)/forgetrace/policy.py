"""
Policy Engine - Configurable Rule Enforcement
Author: Peter Kolawole, BAMG Studio LLC

Provides policy-as-code capabilities for IP auditing, allowing organizations
to codify and enforce compliance rules automatically.

Key Features:
- YAML-based policy definitions
- Support for BLOCK, WARN, INFO actions
- Safe expression evaluation (no code injection)
- Detailed violation reporting
- Policy inheritance and overrides

Example Policy:
    policies:
      - id: no-gpl-licenses
        name: Prohibit GPL Licenses
        severity: HIGH
        action: BLOCK
        condition: "'GPL' in license_types"
        enabled: true
"""

import re
from pathlib import Path
from typing import Any, Dict, List, Optional, Set
from enum import Enum


class PolicyAction(Enum):
    """
    Actions that can be taken when a policy is violated.
    
    BLOCK: Fail the audit (exit code 1) - for critical violations
    WARN: Print warning but continue - for important but not critical issues
    INFO: Log informational message - for awareness only
    """
    BLOCK = "BLOCK"
    WARN = "WARN"
    INFO = "INFO"


class PolicySeverity(Enum):
    """
    Severity levels for policy violations.
    
    Used for prioritization and reporting. Does not affect action taken
    (that's determined by PolicyAction), but helps teams prioritize fixes.
    """
    CRITICAL = "CRITICAL"
    HIGH = "HIGH"
    MEDIUM = "MEDIUM"
    LOW = "LOW"


class PolicyViolation:
    """
    Represents a single policy violation detected during audit.
    
    Contains all information needed to understand, report, and fix the violation.
    """
    
    def __init__(
        self,
        policy_id: str,
        policy_name: str,
        severity: PolicySeverity,
        action: PolicyAction,
        message: str,
        details: Optional[Dict[str, Any]] = None
    ):
        """
        Initialize a policy violation.
        
        Args:
            policy_id: Unique identifier for the violated policy
            policy_name: Human-readable policy name
            severity: Severity level (CRITICAL, HIGH, MEDIUM, LOW)
            action: Action to take (BLOCK, WARN, INFO)
            message: Detailed explanation of the violation
            details: Additional context (e.g., specific files, values)
        """
        self.policy_id = policy_id
        self.policy_name = policy_name
        self.severity = severity
        self.action = action
        self.message = message
        self.details = details or {}
        
    def __repr__(self) -> str:
        return f"PolicyViolation({self.policy_id}, {self.severity.value}, {self.action.value})"


class PolicyEngine:
    """
    Main policy evaluation engine.
    
    Loads policies from YAML configuration and evaluates them against
    audit findings to detect violations.
    
    Design Decisions:
    -----------------
    1. Safe Evaluation: Uses limited expression language instead of eval()
       to prevent code injection attacks
    
    2. Fail-Safe: If policy evaluation fails, logs error but doesn't block
       audit (avoids false positives blocking legitimate work)
    
    3. Atomic Actions: Each policy is independent. One BLOCK violation
       fails entire audit (fail-fast for critical issues)
    
    4. Context Preservation: Violations include full context for debugging
       (what was checked, what value triggered violation, etc.)
    """
    
    def __init__(self, config: Dict[str, Any]) -> None:
        """
        Initialize the policy engine.
        
        Args:
            config: Configuration dictionary containing 'policies' section
        
        Design Note: Takes full config instead of just policies section
        for future expansion (e.g., policy file path, debug mode, etc.)
        """
        self.config = config
        self.policies: List[Dict[str, Any]] = []
        self.violations: List[PolicyViolation] = []
        self._load_policies()
        
    def _load_policies(self) -> None:
        """
        Load and validate policies from configuration.
        
        Performs schema validation to catch errors early (fail-fast principle).
        Invalid policies are logged but not loaded (fail-safe principle).
        
        RATIONALE:
        - Early validation prevents cryptic runtime errors
        - Partial loading allows some policies to work even if others are broken
        - Clear error messages help users fix policy definitions
        """
        raw_policies = self.config.get("policies", [])
        
        if not raw_policies:
            print("â„¹ï¸  No policies configured. Skipping policy enforcement.")
            return
        
        for policy in raw_policies:
            # Validate required fields
            if not self._validate_policy_schema(policy):
                print(f"âš ï¸  Skipping invalid policy: {policy.get('id', 'unknown')}")
                continue
            
            # Only load enabled policies (feature flag pattern)
            if policy.get("enabled", True):
                self.policies.append(policy)
        
        print(f"âœ… Loaded {len(self.policies)} active policies")
    
    def _validate_policy_schema(self, policy: Dict[str, Any]) -> bool:
        """
        Validate that a policy has all required fields with correct types.
        
        Args:
            policy: Policy dictionary from YAML
            
        Returns:
            True if valid, False otherwise
            
        VALIDATION CHECKS:
        1. Required fields present (id, condition, action)
        2. Enum values are valid (action, severity)
        3. Condition is a string (not code object or other dangerous type)
        
        WHY THIS MATTERS:
        - Prevents runtime errors from malformed policies
        - Gives clear feedback about what's wrong
        - Security: Ensures we only evaluate strings, not code objects
        """
        required_fields = ["id", "condition", "action"]
        
        for field in required_fields:
            if field not in policy:
                print(f"âŒ Policy validation failed: Missing required field '{field}'")
                return False
        
        # Validate action is a known enum value
        action = policy["action"].upper()
        if action not in [a.value for a in PolicyAction]:
            print(f"âŒ Policy '{policy['id']}': Invalid action '{action}'. "
                  f"Must be one of: {', '.join(a.value for a in PolicyAction)}")
            return False
        
        # Validate severity if provided
        if "severity" in policy:
            severity = policy["severity"].upper()
            if severity not in [s.value for s in PolicySeverity]:
                print(f"âŒ Policy '{policy['id']}': Invalid severity '{severity}'. "
                      f"Must be one of: {', '.join(s.value for s in PolicySeverity)}")
                return False
        
        # Validate condition is a string (security check)
        if not isinstance(policy["condition"], str):
            print(f"âŒ Policy '{policy['id']}': Condition must be a string")
            return False
        
        return True
    
    def evaluate(self, findings: Dict[str, Any]) -> List[PolicyViolation]:
        """
        Evaluate all policies against audit findings.
        
        Args:
            findings: Complete audit findings from all scanners
            
        Returns:
            List of policy violations detected
            
        ALGORITHM:
        1. For each enabled policy:
           a. Build evaluation context from findings
           b. Safely evaluate condition expression
           c. If condition is True, record violation
        2. Return all violations for reporting
        
        ERROR HANDLING:
        - If policy evaluation crashes, log error but continue
        - Don't let one broken policy break entire audit
        - Track which policies failed for debugging
        
        PERFORMANCE:
        - Policies evaluated in order (deterministic)
        - Could parallelize in future but not worth complexity now
        - Most audits have < 50 policies, evaluation is fast
        """
        self.violations = []
        
        if not self.policies:
            return self.violations
        
        print("\nðŸ” Evaluating policies...")
        
        for policy in self.policies:
            try:
                violated = self._evaluate_policy(policy, findings)
                if violated:
                    violation = self._create_violation(policy, findings)
                    self.violations.append(violation)
                    self._print_violation(violation)
            except Exception as e:
                # Fail-safe: Don't let broken policy crash audit
                print(f"âš ï¸  Error evaluating policy '{policy['id']}': {e}")
                continue
        
        # Summary
        if self.violations:
            self._print_summary()
        else:
            print("âœ… All policies passed!")
        
        return self.violations
    
    def _evaluate_policy(self, policy: Dict[str, Any], findings: Dict[str, Any]) -> bool:
        """
        Evaluate a single policy condition.
        
        Args:
            policy: Policy definition
            findings: Audit findings to check against
            
        Returns:
            True if policy is VIOLATED (condition evaluated to True)
            False if policy is satisfied (condition evaluated to False)
            
        SECURITY - WHY NOT USE eval()?
        ------------------------------
        Using Python's eval() on user input is dangerous:
        
        BAD: eval(policy["condition"], {"findings": findings})
        # User could inject: "__import__('os').system('rm -rf /')"
        
        GOOD: Safe expression evaluator with limited operators
        # Only allow: ==, !=, >, <, in, and, or, not
        # No function calls, imports, or attribute access
        
        CURRENT IMPLEMENTATION:
        - Simple string matching for MVP
        - Future: Use 'simpleeval' library for safe expression evaluation
        
        TRADE-OFFS:
        - Simple: Fast to implement, easy to debug
        - Limited: Can't do complex logic (but 90% of cases are simple)
        - Secure: No code injection risk
        """
        condition = policy["condition"]
        
        # Build evaluation context
        context = self._build_evaluation_context(findings)
        
        # Simple expression evaluation (MVP - will enhance later)
        # For now, support basic checks like:
        # - "license_types contains 'GPL'"
        # - "vulnerability_count.CRITICAL > 0"
        # - "third_party_percentage > 60"
        
        result = self._safe_eval(condition, context)
        return result
    
    def _build_evaluation_context(self, findings: Dict[str, Any]) -> Dict[str, Any]:
        """
        Build the context dictionary for policy evaluation.
        
        Extracts key metrics and values from findings into a flat namespace
        that's easy to reference in policy conditions.
        
        Args:
            findings: Raw audit findings
            
        Returns:
            Dictionary of values accessible in policy conditions
            
        DESIGN DECISION - Flat vs Nested:
        ----------------------------------
        Option 1 (Nested): Keep original structure
          condition: "findings['licenses']['types']['GPL'] > 0"
          Pro: Flexible
          Con: Verbose, error-prone
        
        Option 2 (Flat): Extract common values
          condition: "gpl_license_count > 0"
          Pro: Simple, readable
          Con: Must anticipate all needed values
        
        CHOSEN: Hybrid approach
        - Flatten common values (80% of cases)
        - Keep original findings available for advanced cases
        """
        context: Dict[str, Any] = {}
        
        # License data
        if "licenses" in findings:
            licenses = findings["licenses"]
            context["license_types"] = licenses.get("types", [])
            context["license_count"] = len(context["license_types"])
            
            # Count specific license types
            for license_type in context["license_types"]:
                key = f"license_{license_type.replace('-', '_').replace('.', '_').lower()}_count"
                context[key] = context.get(key, 0) + 1
        
        # Vulnerability data
        if "vulnerabilities" in findings:
            vulns = findings["vulnerabilities"]
            context["vulnerability_count"] = vulns.get("by_severity", {})
            context["total_vulnerabilities"] = vulns.get("total_vulnerabilities", 0)
            context["vulnerable_packages"] = vulns.get("vulnerable_packages", 0)
        
        # SBOM/dependency data
        if "sbom" in findings:
            sbom = findings["sbom"]
            packages = sbom.get("packages", [])
            context["package_count"] = len(packages)
            context["packages"] = packages
        
        # Git/ownership data
        if "git" in findings:
            git = findings["git"]
            context["total_commits"] = git.get("total_commits", 0)
            context["contributors"] = git.get("contributors", [])
            context["contributor_count"] = len(context["contributors"])
        
        # Classification data
        if "classification" in findings:
            classification = findings["classification"]
            context["foreground_files"] = classification.get("foreground", [])
            context["background_files"] = classification.get("background", [])
            context["third_party_files"] = classification.get("third_party", [])
            
            total = len(context["foreground_files"]) + len(context["background_files"]) + len(context["third_party_files"])
            if total > 0:
                context["third_party_percentage"] = (len(context["third_party_files"]) / total) * 100
            else:
                context["third_party_percentage"] = 0
        
        # Keep raw findings for advanced queries
        context["findings"] = findings
        
        return context
    
    def _safe_eval(self, condition: str, context: Dict[str, Any]) -> bool:
        """
        Safely evaluate a policy condition expression.
        
        Args:
            condition: Expression string (e.g., "vulnerability_count.CRITICAL > 0")
            context: Variables available in the expression
            
        Returns:
            True if condition is met (violation), False otherwise
            
        IMPLEMENTATION STRATEGY (MVP):
        -----------------------------
        Phase 1 (Now): Pattern matching for common cases
        - "X contains Y"
        - "X > N", "X < N", "X == N"
        - "X in [A, B, C]"
        
        Phase 2 (Future): Full expression evaluator
        - Use 'simpleeval' library
        - Support: and, or, not, parentheses
        - Example: "(GPL in licenses) and (critical_vulns > 0)"
        
        WHY PATTERN MATCHING FIRST?
        - Faster to implement (15 minutes vs 2 hours)
        - Covers 80% of real-world cases
        - No external dependencies
        - Easy to understand and debug
        """
        condition = condition.strip()
        
        # Pattern 1: "X contains Y" or "'Y' in X"
        contains_match = re.match(r"['\"](.+?)['\"]\s+in\s+(\w+)", condition)
        if contains_match:
            value, var_name = contains_match.groups()
            if var_name in context:
                container = context[var_name]
                if isinstance(container, (list, set)):
                    return value in container
                if isinstance(container, str):
                    return value in container
        
        # Pattern 2: "X > N", "X < N", "X >= N", "X <= N"
        comparison_match = re.match(r"(\w+(?:\.\w+)?)\s*([><=!]+)\s*(\d+(?:\.\d+)?)", condition)
        if comparison_match:
            var_path, operator, value_str = comparison_match.groups()
            
            # Navigate nested paths like "vulnerability_count.CRITICAL"
            var_value = self._get_nested_value(context, var_path)
            
            if var_value is not None:
                value = float(value_str) if '.' in value_str else int(value_str)
                
                if operator == ">":
                    return var_value > value
                elif operator == "<":
                    return var_value < value
                elif operator == ">=":
                    return var_value >= value
                elif operator == "<=":
                    return var_value <= value
                elif operator == "==":
                    return var_value == value
                elif operator == "!=":
                    return var_value != value
        
        # Pattern 3: "X == 'string'"
        string_eq_match = re.match(r"(\w+)\s*==\s*['\"](.+?)['\"]", condition)
        if string_eq_match:
            var_name, value = string_eq_match.groups()
            if var_name in context:
                return context[var_name] == value
        
        # If no pattern matched, log warning and return False (fail-safe)
        print(f"âš ï¸  Could not parse condition: '{condition}'. Skipping.")
        return False
    
    def _get_nested_value(self, context: Dict[str, Any], path: str) -> Any:
        """
        Get value from nested dictionary using dot notation.
        
        Example: "vulnerability_count.CRITICAL" -> context["vulnerability_count"]["CRITICAL"]
        
        Args:
            context: Context dictionary
            path: Dot-separated path to value
            
        Returns:
            Value at path, or None if not found
        """
        parts = path.split(".")
        value = context
        
        for part in parts:
            if isinstance(value, dict) and part in value:
                value = value[part]
            else:
                return None
        
        return value
    
    def _create_violation(self, policy: Dict[str, Any], findings: Dict[str, Any]) -> PolicyViolation:
        """
        Create a PolicyViolation object from a violated policy.
        
        Args:
            policy: Policy that was violated
            findings: Audit findings (for extracting details)
            
        Returns:
            PolicyViolation instance with full context
        """
        severity = PolicySeverity[policy.get("severity", "MEDIUM").upper()]
        action = PolicyAction[policy["action"].upper()]
        
        message = policy.get(
            "description",
            f"Policy '{policy.get('name', policy['id'])}' was violated"
        )
        
        # Add condition for debugging
        details = {
            "condition": policy["condition"],
            "policy_id": policy["id"]
        }
        
        return PolicyViolation(
            policy_id=policy["id"],
            policy_name=policy.get("name", policy["id"]),
            severity=severity,
            action=action,
            message=message,
            details=details
        )
    
    def _print_violation(self, violation: PolicyViolation) -> None:
        """Print a policy violation to console with formatting."""
        icon = {
            PolicyAction.BLOCK: "ðŸš«",
            PolicyAction.WARN: "âš ï¸ ",
            PolicyAction.INFO: "â„¹ï¸ "
        }[violation.action]
        
        print(f"\n{icon} {violation.severity.value} - {violation.policy_name}")
        print(f"   {violation.message}")
        print(f"   Condition: {violation.details.get('condition', 'N/A')}")
    
    def _print_summary(self) -> None:
        """Print summary of all violations."""
        blocks = [v for v in self.violations if v.action == PolicyAction.BLOCK]
        warns = [v for v in self.violations if v.action == PolicyAction.WARN]
        infos = [v for v in self.violations if v.action == PolicyAction.INFO]
        
        print(f"\n{'=' * 60}")
        print(f"Policy Violations Summary:")
        print(f"  ðŸš« BLOCK: {len(blocks)} (audit will fail)")
        print(f"  âš ï¸  WARN:  {len(warns)} (warnings only)")
        print(f"  â„¹ï¸  INFO:  {len(infos)} (informational)")
        print(f"{'=' * 60}\n")
    
    def should_fail_audit(self) -> bool:
        """
        Determine if audit should fail based on violations.
        
        Returns:
            True if any BLOCK-level violations exist
            
        RATIONALE:
        - Fail-fast: One critical violation should stop deployment
        - Clear signal: Exit code 1 tells CI to fail the build
        - Actionable: User knows they must fix BLOCK violations
        """
        return any(v.action == PolicyAction.BLOCK for v in self.violations)
    
    def get_violations_by_severity(self) -> Dict[PolicySeverity, List[PolicyViolation]]:
        """
        Group violations by severity for reporting.
        
        Returns:
            Dictionary mapping severity levels to violation lists
        """
        result: Dict[PolicySeverity, List[PolicyViolation]] = {
            severity: [] for severity in PolicySeverity
        }
        
        for violation in self.violations:
            result[violation.severity].append(violation)
        
        return result
